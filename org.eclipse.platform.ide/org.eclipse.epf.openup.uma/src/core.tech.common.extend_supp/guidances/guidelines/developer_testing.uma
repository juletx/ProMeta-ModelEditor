<?xml version="1.0" encoding="UTF-8"?>
<org.eclipse.epf.uma:ContentDescription xmi:version="2.0" xmlns:xmi="http://www.omg.org/XMI" xmlns:org.eclipse.epf.uma="http://www.eclipse.org/epf/uma/1.0.6/uma.ecore" xmi:id="-wuu2cNRUPlrBuaO0OdzLFg" name=",_ByOd4O6pEduvoopEslG-4g" guid="-wuu2cNRUPlrBuaO0OdzLFg" changeDate="2008-08-14T13:53:04.000+0200" version="1.0.0" mainDescription="&lt;h3>&#xD;&#xA;    Establish expectations&#xD;&#xA;&lt;/h3>&#xD;&#xA;&lt;p>&#xD;&#xA;    Those who find developer testing rewarding do it. Those who view it as a chore find ways to avoid it. This is simply in&#xD;&#xA;    the nature of most developers in most industries, and treating it as a shameful lack of discipline hasn't historically&#xD;&#xA;    been successful. Therefore, as a developer you should expect testing to be rewarding and do what it takes to make it&#xD;&#xA;    rewarding.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Ideal developer testing follows a very tight edit-test loop. You make a small change to the product, such as adding a&#xD;&#xA;    new method to a class, then you immediately rerun your tests. If any test breaks, you know exactly what code is the&#xD;&#xA;    cause. This easy, steady pace of development is the greatest reward of developer testing. A long debugging session&#xD;&#xA;    should be exceptional.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Because it's not unusual for a change made in one class to break something in another, you should expect to rerun not&#xD;&#xA;    just the changed class's tests, but many tests. Ideally, you rerun the complete test suite for your implementation&#xD;&#xA;    element many times per hour. Every time you make a significant change, you rerun the suite, watch the results, and&#xD;&#xA;    either proceed to the next change or fix the last change. Expect to spend some effort making that rapid feedback&#xD;&#xA;    possible.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h3>&#xD;&#xA;    Write and maintain&amp;nbsp;tests&#xD;&#xA;&lt;/h3>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Automate your tests&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Running tests often is not practical if tests are manual. For some implementation elements, automated tests are easy.&#xD;&#xA;    An example would be an in-memory database. It communicates to its clients through an API and has no other interface to&#xD;&#xA;    the outside world. Tests for it would look something like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;/* Check that elements can be added at most once. */&#xD;&#xA;// Setup&#xD;&#xA;Database db = new Database();&#xD;&#xA;db.add(&quot;key1&quot;, &quot;value1&quot;);&#xD;&#xA;// Test&#xD;&#xA;boolean result = db.add(&quot;key1&quot;, &quot;another value&quot;);&#xD;&#xA;expect(result == false);&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    The tests are different from ordinary client code in only one way: instead of believing the results of API calls, they&#xD;&#xA;    check. If the API makes client code easy to write, it makes test code easy to write. If the test code is &lt;i>not&lt;/i>&#xD;&#xA;    easy to write, you've received an early warning that the API could be improved. Test-first design is thus consistent&#xD;&#xA;    with the iterative processes' focus on addressing important risks early.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    The more tightly connected the element is to the outside world, however, the harder it will be to test. There are two&#xD;&#xA;    common cases: graphical user interfaces and back-end components.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h5>&#xD;&#xA;    Graphical user interfaces&#xD;&#xA;&lt;/h5>&#xD;&#xA;&lt;p>&#xD;&#xA;    Suppose the database in the example above receives its data via a callback from a user-interface object. The callback&#xD;&#xA;    is invoked when the user fills in some text fields and pushes a button. Testing this by manually filling in the fields&#xD;&#xA;    and pushing the button isn't something you want to do many times an hour. You must arrange a way to deliver the input&#xD;&#xA;    under programmatic control, typically by &quot;pushing&quot; the button in code.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Pushing the button causes some code in the implementation element to be executed. Most likely, that code changes the&#xD;&#xA;    state of some user-interface objects. So you must also arrange a way to query those objects programmatically.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h5>&#xD;&#xA;    Back-end components&#xD;&#xA;&lt;/h5>&#xD;&#xA;&lt;p>&#xD;&#xA;    Suppose the element under test doesn't implement a database. Instead, it's a wrapper around a real, on-disk database.&#xD;&#xA;    Testing against that real database might be difficult. It might be hard to install and configure. Licenses for it might&#xD;&#xA;    be expensive. The database might slow down the tests enough that you're not inclined to run them often. In such cases,&#xD;&#xA;    it's worthwhile to &quot;stub out&quot; the database with a simpler element that does just enough to support the tests.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Stubs are also useful when a component that your element talks to isn't ready yet. You don't want your testing to wait&#xD;&#xA;    on someone else's code.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Don't write your own tools&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Developer testing seems pretty straightforward. You set up some objects, make a call through an API, check the result,&#xD;&#xA;    and announce a test failure if the results aren't as expected. It's also convenient to have some way to group tests so&#xD;&#xA;    that they can be run individually or as complete suites. Tools that support those requirements are called &lt;i>test&#xD;&#xA;    frameworks&lt;/i>.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Developer testing &lt;b>is&lt;/b> straightforward, and the requirements for test frameworks are not complicated. If, however,&#xD;&#xA;    you yield to the temptation of writing your own test framework, you'll spend much more time tinkering with the&#xD;&#xA;    framework than you probably expect. There are many test frameworks available, both commercial and open source, and&#xD;&#xA;    there's no reason not to use one of those.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Do create support code&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Test code tends to be repetitive. It's common to see sequences of code like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;// null name not allowed&#xD;&#xA;retval = o.createName(&quot;&quot;); &#xD;&#xA;expect(retval == null);&#xD;&#xA;// leading spaces not allowed&#xD;&#xA;retval = o.createName(&quot; l&quot;); &#xD;&#xA;expect(retval == null);&#xD;&#xA;// trailing spaces not allowed&#xD;&#xA;retval = o.createName(&quot;name &quot;); &#xD;&#xA;expect(retval == null);&#xD;&#xA;// first character may not be numeric&#xD;&#xA;retval = o.createName(&quot;5allpha&quot;); &#xD;&#xA;expect(retval == null);&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    This code is created by copying one check, pasting it, then editing it to make another check.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    The danger here is twofold. If the interface changes, much editing will have to be done. (In more complicated cases, a&#xD;&#xA;    simple global replacement won't suffice.) Also, if the code is at all complicated, the intent of the test can be lost&#xD;&#xA;    amid all the text.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    When you find yourself repeating yourself, seriously consider factoring out the repetition into support code. Even&#xD;&#xA;    though the code above is a simple example, it's more readable and maintainable if written like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;void expectNameRejected(MyClass o, String s) {&#xD;&#xA;Object retval = o.createName(s);&#xD;&#xA;expect(retval == null);&#xD;&#xA;}&#xD;&#xA;...&#xD;&#xA;// null name not allowed&#xD;&#xA;expectNameRejected(o, &quot;&quot;); &#xD;&#xA;// leading spaces not allowed.&#xD;&#xA;expectNameRejected(o, &quot; l&quot;); &#xD;&#xA;// trailing spaces not allowed.&#xD;&#xA;expectNameRejected(o, &quot;name &quot;); &#xD;&#xA;// first character may not be numeric.&#xD;&#xA;expectNameRejected(o, &quot;5alpha&quot;); &#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    Developers writing tests often err on the side of too much copying-and-pasting. If you suspect yourself of that&#xD;&#xA;    tendency, it's useful to consciously err in the other direction. Resolve that you will strip your code of all duplicate&#xD;&#xA;    text.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Keep the tests understandable&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    You should expect that you, or someone else, will have to modify the tests later. A typical situation is that a later&#xD;&#xA;    iteration calls for a change to the element's behavior. As a simple example, suppose the element once declared a square&#xD;&#xA;    root method like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;    &lt;p>&#xD;&#xA;        &lt;font size=&quot;+0&quot;>double sqrt(double x);&lt;/font>&#xD;&#xA;    &lt;/p>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    In that version, a negative argument caused the function &quot;sqrt&quot; to return NaN (&quot;not a number&quot; from the IEEE 754-1985&#xD;&#xA;    &lt;i>Standard for Binary Floating-Point Arithmetic&lt;/i>). In the new iteration, the square root method will accept&#xD;&#xA;    negative numbers and return a complex result:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;    &lt;p>&#xD;&#xA;        &lt;font size=&quot;+0&quot;>Complex sqrt(double x);&lt;/font>&#xD;&#xA;    &lt;/p>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    Old tests for the function &quot;sqrt&quot; will have to change. That means understanding what they do, and updating them so that&#xD;&#xA;    they work with the new &quot;sqrt&quot;. When updating tests, you must take care not to destroy their bug-finding power. One way&#xD;&#xA;    that sometimes happens is this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;void testSQRT () {&#xD;&#xA;//  Update these tests for Complex &#xD;&#xA;// when I have time -- bem&#xD;&#xA;/*&#xD;&#xA;double result = sqrt(0.0);&#xD;&#xA;...&#xD;&#xA;*/&#xD;&#xA;}&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    Other ways are more subtle: the tests are changed so that they actually run, but they no longer test what they were&#xD;&#xA;    originally intended to test. The end result, over many iterations, can be a test suite that is too weak to catch many&#xD;&#xA;    bugs. This is sometimes called &quot;test suite decay&quot;. A decayed suite will be abandoned, because it's not worth the&#xD;&#xA;    upkeep.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Test suite decay is less likely in the direct tests for the function &quot;sqrt&quot; than in indirect tests. There will be code&#xD;&#xA;    that calls the function &quot;sqrt&quot;. That code will have tests. When the function &quot;sqrt&quot; changes, some of those tests will&#xD;&#xA;    fail. The person who changes the function &quot;sqrt&quot; will probably have to change those tests. Because he's less familiar&#xD;&#xA;    with them, and because their relationship to the change is less clear, he's more likely to weaken them in the process&#xD;&#xA;    of making them pass.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    When you're creating support code for tests (as urged above), be careful: the support code should clarify, not obscure,&#xD;&#xA;    the purpose of the tests that use it. A common complaint about object-oriented programs is that there's no one place&#xD;&#xA;    where anything's done. If you look at any one method, all you discover is that it forwards its work somewhere else.&#xD;&#xA;    Such a structure has advantages, but it makes it harder for new people to understand the code. Unless they make an&#xD;&#xA;    effort, their changes are likely to be incorrect or to make the code even more complicated and fragile. The same is&#xD;&#xA;    true of test code, except that later maintainers are even less likely to take due care. You must head off the problem&#xD;&#xA;    by writing understandable tests.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Match the test structure to the product structure&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Suppose someone has inherited your implementation element. They need to change a part of it. They may want to examine&#xD;&#xA;    the old tests to help them in their new design. They want to update the old tests before writing the code (test-first&#xD;&#xA;    design).&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    All those good intentions will go by the wayside if they can't find the appropriate tests. What they'll do is make the&#xD;&#xA;    change, see what tests fail, then fix those. That will contribute to test suite decay.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    For that reason, it's important that the test suite be well structured, and that the location of tests be predictable&#xD;&#xA;    from the structure of the product. Most usually, developers arrange tests in a parallel hierarchy, with one test class&#xD;&#xA;    per product class. So if someone is changing a class named &quot;Log&quot;, they know the test class is &quot;TestLog&quot;, and they know&#xD;&#xA;    where the source file can be found.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Let tests violate encapsulation&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    You might limit your tests to interacting with your implementation element exactly as client code does, through the&#xD;&#xA;    same interface that client code uses. However, this has disadvantages. Suppose you're testing a simple class that&#xD;&#xA;    maintains a doubly linked list:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    In particular, you're testing the &quot;DoublyLinkedList.insertBefore(Object existing, Object newObject)&quot; method. In one of&#xD;&#xA;    your tests, you want to insert an element in the middle of the list, then check if it's been inserted successfully. The&#xD;&#xA;    test uses the list above to create this updated list:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    It checks the list correctness like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;// the list is now one longer. &#xD;&#xA;expect(list.size()==3);&#xD;&#xA;// the new element is in the correct position&#xD;&#xA;expect(list.get(1)==m);&#xD;&#xA;// check that other elements are still there.&#xD;&#xA;expect(list.get(0)==a);&#xD;&#xA;expect(list.get(2)==z);&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    That seems sufficient, but it's not. Suppose the list implementation is incorrect and backward pointers are not set&#xD;&#xA;    correctly. That is, suppose the updated list actually looks like this:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    If the function &quot;DoublyLinkedList.get(int index)&quot; traverses the list from the beginning to the end (likely), the test&#xD;&#xA;    would miss this failure. If the class provides &quot;elementBefore&quot; and &quot;elementAfter&quot; methods, checking for such failures&#xD;&#xA;    is straightforward:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;// Check that links were all updated&#xD;&#xA;expect(list.elementAfter(a)==m);&#xD;&#xA;expect(list.elementAfter(m)==z);&#xD;&#xA;expect(list.elementBefore(z)==m); //this will fail&#xD;&#xA;expect(list.elementBefore(m)==a);&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    But what if it doesn't provide those methods? You could devise more elaborate sequences of method calls that will fail&#xD;&#xA;    if the suspected defect is present. For example, this would work:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;// Check whether back-link from Z is correct.&#xD;&#xA;list.insertBefore(z, x);&#xD;&#xA;// If it was incorrectly not updated, X will have &#xD;&#xA;// been inserted just after A.&#xD;&#xA;expect(list.get(1)==m); &#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    But such a test is more work to create and is likely to be significantly harder to maintain. (Unless you write good&#xD;&#xA;    comments, it will not be at all clear why the test is doing what it's doing.) There are two solutions:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;ol>&#xD;&#xA;    &lt;li>&#xD;&#xA;        Add the &quot;elementBefore&quot; and &quot;elementAfter&quot; methods to the public interface. But that effectively exposes the&#xD;&#xA;        implementation to everyone and makes future change more difficult.&#xD;&#xA;    &lt;/li>&#xD;&#xA;    &lt;li>&#xD;&#xA;        Let the tests &quot;look under the hood&quot; and check pointers directly.&#xD;&#xA;    &lt;/li>&#xD;&#xA;&lt;/ol>&#xD;&#xA;&lt;p>&#xD;&#xA;    The latter is usually the best solution, even for a simple class like &quot;DoublyLinkedList&quot; and especially for the more&#xD;&#xA;    complex classes that occur in your products.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Typically, tests are put in the same package as the class they test. They are given protected or friend access.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Approaches for Test Setup&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    To successfully run a test, the system must be in a known state. To do this you will need objects or components in&#xD;&#xA;    memory, rows in the database, etc. that you will test against. The easiest approach is to hardcode the required data&#xD;&#xA;    and the setup code within the test itself. The primary advantage is that all the information that you need about the&#xD;&#xA;    test is in one place and that the test is potentially self-sufficient.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Another approach is to define an external data set which is loaded into memory or into the database at the beginning of&#xD;&#xA;    the test run. There are several advantages to this approach:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;ul>&#xD;&#xA;    &lt;li>&#xD;&#xA;        It decouples the test data from the test.&#xD;&#xA;    &lt;/li>&#xD;&#xA;    &lt;li>&#xD;&#xA;        More than one test can use the same data set.&#xD;&#xA;    &lt;/li>&#xD;&#xA;    &lt;li>&#xD;&#xA;        It is easy to modify and/or multiply the test data.&#xD;&#xA;    &lt;/li>&#xD;&#xA;&lt;/ul>&#xD;&#xA;&lt;p>&#xD;&#xA;    There are some disadvantages to this approach:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;ul>&#xD;&#xA;    &lt;li>&#xD;&#xA;        Increased complexity for maintaining the external data&#xD;&#xA;    &lt;/li>&#xD;&#xA;    &lt;li>&#xD;&#xA;        Potential coupling between test cases. When they share a common test data bed it becomes very easy to write tests&#xD;&#xA;        that depend on other tests running first, thereby coupling them together.&#xD;&#xA;    &lt;/li>&#xD;&#xA;&lt;/ul>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Coding for Testability&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Add&amp;nbsp;&lt;a class=&quot;elementLink&quot;&#xD;&#xA;    href=&quot;./../../../core.tech.common.base/guidances/termdefinitions/code_instrumentation_3060875F.html&quot;&#xD;&#xA;    guid=&quot;_lzAWkK9eEdyltJ0KgEd9WQ&quot;>code instrumentation&lt;/a> for testing and debugging. Pay special attention to the&#xD;&#xA;    implementation of the observation/control points, such as critical functions or objects, as these aspects might need&#xD;&#xA;    special support that has to be implemented in the application under test.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Reviewing Tests&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    If a test will be long-lived, ask a person with less inside knowledge of the implementation element to run it and check&#xD;&#xA;    if there is enough support information. Review it with other people within the development team and other interested&#xD;&#xA;    parties as needed.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h3>&#xD;&#xA;    &lt;a id=&quot;TestDesignMistakes&quot; name=&quot;TestDesignMistakes&quot;>&lt;/a>Characteristic Test Design Mistakes&#xD;&#xA;&lt;/h3>&#xD;&#xA;&lt;p>&#xD;&#xA;    Each test exercises an implementation element and checks for correct results. The design of the test-the inputs it uses&#xD;&#xA;    and how it checks for correctness-can be good at revealing defects, or it can inadvertently hide them. Here are some&#xD;&#xA;    characteristic test design mistakes.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to specify expected results in advance&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Suppose you're testing an implementation element that converts XML into HTML. A temptation is to take some sample XML,&#xD;&#xA;    run it through the conversion, then look at the results in a browser. If the screen looks right, you &quot;bless&quot; the HTML&#xD;&#xA;    by saving it as the official expected results. Thereafter, a test compares the actual output of the conversion to the&#xD;&#xA;    expected results.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    This is a dangerous practice. Even sophisticated computer users are used to believing what the computer does. You are&#xD;&#xA;    likely to overlook mistakes in the screen appearance. (Not to mention that browsers are quite tolerant of misformatted&#xD;&#xA;    HTML.) By making that incorrect HTML the official expected results, you make sure that the test can never find the&#xD;&#xA;    problem.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    It's less dangerous to doubly-check by looking directly at the HTML, but it's still dangerous. Because the output is&#xD;&#xA;    complicated, it will be easy to overlook errors. You'll find more defects if you write the expected output by hand&#xD;&#xA;    first.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to check the background&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Tests usually check that what should have been changed has been, but their creators often forget to check that what&#xD;&#xA;    should have been left alone has been left alone. For example, suppose a program is supposed to change the first 100&#xD;&#xA;    records in a file. It's a good idea to check that the 101&lt;sup>st&lt;/sup> hasn't been changed.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    In theory, you would check that nothing in the &quot;background&quot;-the entire file system, all of memory, everything reachable&#xD;&#xA;    through the network-has been left alone. In practice, you have to choose carefully what you can afford to check. But&#xD;&#xA;    it's important to make that choice.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to check persistence&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Just because the implementation element tells you a change has been made, that doesn't mean it has actually been&#xD;&#xA;    committed to the database. You need to check the database via another route.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to add variety&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    A test might be designed to check the effect of three fields in a database record, but many other fields need to be&#xD;&#xA;    filled in to execute the test. Testers will often use the same values over and over again for these &quot;irrelevant&quot;&#xD;&#xA;    fields. For example, they'll always use the name of their lover in a text field, or 999 in a numeric field.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    The problem is that sometimes what shouldn't matter actually does. Every so often, there's a bug that depends on some&#xD;&#xA;    obscure combination of unlikely inputs. If you always use the same inputs, you stand no chance of finding such bugs. If&#xD;&#xA;    you persistently vary inputs, you might. Quite often, it costs almost nothing to use a number different than 999 or to&#xD;&#xA;    use someone else's name. When varying the values used in tests costs almost nothing and it has some potential benefit,&#xD;&#xA;    then vary. (Note: It's unwise to use names of old lovers instead of your current one if your current lover works with&#xD;&#xA;    you.)&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    Here's another benefit. One plausible fault is for the program to use field &lt;i>X&lt;/i> when it should have used field&#xD;&#xA;    &lt;i>Y&lt;/i>. If both fields contain &quot;Dawn&quot;, the fault can't be detected.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to use realistic data&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    It's common to use made-up data in tests. That data is often unrealistically simple. For example, customer names might&#xD;&#xA;    be &quot;Mickey&quot;, &quot;Snoopy&quot;, and &quot;Donald&quot;. Because that data is different from what real users enter - for example, it's&#xD;&#xA;    characteristically shorter - it can miss defects real customers will see. For example, these one-word names wouldn't&#xD;&#xA;    detect that the code doesn't handle names with spaces.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    It's prudent to make a slight extra effort to use realistic data.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to notice that the code does nothing at all&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Suppose you initialize a database record to zero, run a calculation that should result in zero being stored in the&#xD;&#xA;    record, then check that the record is zero. What has your test demonstrated? The calculation might not have taken place&#xD;&#xA;    at all. Nothing might have been stored, and the test couldn't tell.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    That example sounds unlikely. But this same mistake can crop up in subtler ways. For example, you might write a test&#xD;&#xA;    for a complicated installer program. The test is intended to check that all temporary files are removed after a&#xD;&#xA;    successful installation. But, because of all the installer options, in that test, one particular temporary file wasn't&#xD;&#xA;    created. Sure enough, that's the one the program forgot to remove.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;h4>&#xD;&#xA;    Failure to notice that the code does the wrong thing&#xD;&#xA;&lt;/h4>&#xD;&#xA;&lt;p>&#xD;&#xA;    Sometimes a program does the right thing for the wrong reasons. As a trivial example, consider this code:&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;blockquote>&#xD;&#xA;&lt;pre>&#xD;&#xA;&lt;!-- START NON-TRANSLATABLE -->&#xD;&#xA;if (a &amp;lt; b &amp;amp;&amp;amp; c) &#xD;&#xA;return 2 * x;&#xD;&#xA;else&#xD;&#xA;return x * x;&#xD;&#xA;&lt;!-- END NON-TRANSLATABLE -->&#xD;&#xA;&lt;/pre>&#xD;&#xA;&lt;/blockquote>&#xD;&#xA;&lt;p>&#xD;&#xA;    The logical expression is wrong, and you've written a test that causes it to evaluate incorrectly and take the wrong&#xD;&#xA;    branch. Unfortunately, purely by coincidence, the variable X has the value 2 in that test. So the result of the wrong&#xD;&#xA;    branch is accidentally correct - the same as the result the right branch would have given.&#xD;&#xA;&lt;/p>&#xD;&#xA;&lt;p>&#xD;&#xA;    For each expected result, you should ask if there's a plausible way in which that result could be&amp;nbsp;achieved for the&#xD;&#xA;    wrong reason. While it's often impossible to know, sometimes it's not.&#xD;&#xA;&lt;/p>" longPresentationName=",_ByOd4O6pEduvoopEslG-4g"/>
